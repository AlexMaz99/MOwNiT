{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Laboratorium 4 - Singular Value Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Aleksandra Mazur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1 Wyszukiwarka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. \n",
    "Przygotuj duży (> 1000 elementów) zbiór dokumentów tekstowych w języku angielskim\n",
    "(np. wybrany korpus tekstów, podzbiór artykułów Wikipedii, zbiór dokumentów\n",
    "HTML uzyskanych za pomoca Web crawlera, zbiór rozdziałów wyciętych z\n",
    "różnych książek)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ze strony https://ebible.org/find/details.php?id=eng-web&all=1 pobrano zbiór dokumentów tekstowych w języku angielskim, liczący 1100 plików."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej przedstawiono kilka przykładowych plików."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "\n",
    "files = os.listdir('documents/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_two_files(files):\n",
    "    i = 0\n",
    "    for file in files:\n",
    "        f = io.open('documents/' + file, encoding=\"utf8\")\n",
    "        text_from_file = f.read()\n",
    "        print(\"File number: \", i)\n",
    "        print(text_from_file)\n",
    "        i += 1\n",
    "        if i == 2:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File number:  0\n",
      "﻿This set of files contains a script of canonical text, chapter by chapter,\n",
      "for the purpose of reading to make an audio recording.\n",
      "All footnotes, introductions, and verse numbers have been stripped out.\n",
      "\n",
      "\n",
      "File number:  1\n",
      "﻿The First Book of Moses, Commonly Called Genesis.\n",
      "Chapter 1.\n",
      "In the beginning, God created the heavens and the earth. \n",
      "The earth was formless and empty. Darkness was on the surface of the deep and God’s Spirit was hovering over the surface of the waters. \n",
      "God said, “Let there be light,” and there was light. \n",
      "God saw the light, and saw that it was good. God divided the light from the darkness. \n",
      "God called the light “day”, and the darkness he called “night”. There was evening and there was morning, the first day. \n",
      "God said, “Let there be an expanse in the middle of the waters, and let it divide the waters from the waters.” \n",
      "God made the expanse, and divided the waters which were under the expanse from the waters which were above the expanse; and it was so. \n",
      "God called the expanse “sky”. There was evening and there was morning, a second day. \n",
      "God said, “Let the waters under the sky be gathered together to one place, and let the dry land appear;” and it was so. \n",
      "God called the dry land “earth”, and the gathering together of the waters he called “seas”. God saw that it was good. \n",
      "God said, “Let the earth yield grass, herbs yielding seeds, and fruit trees bearing fruit after their kind, with their seeds in it, on the earth;” and it was so. \n",
      "The earth yielded grass, herbs yielding seed after their kind, and trees bearing fruit, with their seeds in it, after their kind; and God saw that it was good. \n",
      "There was evening and there was morning, a third day. \n",
      "God said, “Let there be lights in the expanse of the sky to divide the day from the night; and let them be for signs to mark seasons, days, and years; \n",
      "and let them be for lights in the expanse of the sky to give light on the earth;” and it was so. \n",
      "God made the two great lights: the greater light to rule the day, and the lesser light to rule the night. He also made the stars. \n",
      "God set them in the expanse of the sky to give light to the earth, \n",
      "and to rule over the day and over the night, and to divide the light from the darkness. God saw that it was good. \n",
      "There was evening and there was morning, a fourth day. \n",
      "God said, “Let the waters abound with living creatures, and let birds fly above the earth in the open expanse of the sky.” \n",
      "God created the large sea creatures and every living creature that moves, with which the waters swarmed, after their kind, and every winged bird after its kind. God saw that it was good. \n",
      "God blessed them, saying, “Be fruitful, and multiply, and fill the waters in the seas, and let birds multiply on the earth.” \n",
      "There was evening and there was morning, a fifth day. \n",
      "God said, “Let the earth produce living creatures after their kind, livestock, creeping things, and animals of the earth after their kind;” and it was so. \n",
      "God made the animals of the earth after their kind, and the livestock after their kind, and everything that creeps on the ground after its kind. God saw that it was good. \n",
      "God said, “Let’s make man in our image, after our likeness. Let them have dominion over the fish of the sea, and over the birds of the sky, and over the livestock, and over all the earth, and over every creeping thing that creeps on the earth.” \n",
      "God created man in his own image. In God’s image he created him; male and female he created them. \n",
      "God blessed them. God said to them, “Be fruitful, multiply, fill the earth, and subdue it. Have dominion over the fish of the sea, over the birds of the sky, and over every living thing that moves on the earth.” \n",
      "God said, “Behold, I have given you every herb yielding seed, which is on the surface of all the earth, and every tree, which bears fruit yielding seed. It will be your food. \n",
      "To every animal of the earth, and to every bird of the sky, and to everything that creeps on the earth, in which there is life, I have given every green herb for food;” and it was so. \n",
      "God saw everything that he had made, and, behold, it was very good. There was evening and there was morning, a sixth day. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_two_files(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. \n",
    "Określ słownik słów kluczowych (termów) potrzebny do wyznaczenia wektorów\n",
    "cech bag-of-words (indeksacja). Przykładowo zbiorem takim może być unia wszystkich\n",
    "słów występujących we wszystkich tekstach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Słownik słów kluczowych określono jako unię wszystkich słów występujących we wszystkich tekstach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dictionary(files):\n",
    "    words_with_quantity = {}\n",
    "    dictionary = []\n",
    "    \n",
    "    for file in files:\n",
    "        f = io.open('documents/' + file, encoding=\"utf8\")\n",
    "        text_from_file = f.read()\n",
    "        f.close()\n",
    "        sentences = text_from_file.split('\\n')\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.lower()\n",
    "            sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "            sentence = re.sub('[0-9]', '', sentence)\n",
    "            words = nltk.word_tokenize(sentence)\n",
    "            dictionary.extend(words)\n",
    "            \n",
    "            for word in words:\n",
    "                if word in words_with_quantity.keys():\n",
    "                    words_with_quantity[word] += 1\n",
    "                else:\n",
    "                    words_with_quantity[word] = 1\n",
    "                    \n",
    "    dictionary = sorted(list(set(dictionary)))\n",
    "    return dictionary, words_with_quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary, words_with_quantity = create_dictionary(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej przedstawiono 10 słów, które najczęściej pojawiały się w plikach tekstowych wraz z ilością ich występowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_most_popular_words(quantity, words_with_quantity):\n",
    "    words_list = sorted(words_with_quantity.items(), key = lambda x: x[1], reverse=True)\n",
    "    print(\"Liczba słów w słowniku: \", len(words_with_quantity))\n",
    "    print(quantity, \" najpopularniejszych słów:\")\n",
    "    for i, element in enumerate(words_list):\n",
    "        print(element[0], \" -> \", element[1])\n",
    "        if i == quantity:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba słów w słowniku:  13675\n",
      "10  najpopularniejszych słów:\n",
      "the  ->  53774\n",
      "of  ->  31534\n",
      "and  ->  30339\n",
      "to  ->  19633\n",
      "you  ->  12157\n",
      "in  ->  12045\n",
      "he  ->  9289\n",
      "will  ->  9088\n",
      "a  ->  8511\n",
      "for  ->  8391\n",
      "his  ->  8215\n"
     ]
    }
   ],
   "source": [
    "show_most_popular_words(10, words_with_quantity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.\n",
    "Dla każdego dokumentu j wyznacz wektor cech bag-of-words dj zawierający częstości\n",
    "występowania poszczególnych słów (termów) w tekście."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector(file, dictionary):\n",
    "    bow = {}\n",
    "    for word in dictionary:\n",
    "        bow[word] = 0\n",
    "    f = io.open('documents/' + file, encoding=\"utf8\")\n",
    "    text_from_file = f.read()\n",
    "    f.close()\n",
    "    sentences = text_from_file.split('\\n')\n",
    "\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.lower()\n",
    "        sentence = re.sub(r'[^\\w\\s]', '', sentence)\n",
    "        sentence = re.sub('[0-9]', '', sentence)\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        dictionary.extend(words)\n",
    "\n",
    "        for word in words:\n",
    "            bow[word] += 1\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(quantity, files, dictionary):\n",
    "    for i, file in enumerate(files):\n",
    "        print (\"\\nFile number: \", i)\n",
    "        bow = create_vector(file, dictionary)\n",
    "        bow_sorted = sorted(bow.items(), key = lambda x: x[1], reverse=True)\n",
    "        for element in bow_sorted:\n",
    "            if (element[1] == 0):\n",
    "                break\n",
    "            print(element[0], \" -> \", element[1])\n",
    "\n",
    "        if i == quantity:\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej znajdują się wektory cech bag-of-words dla dwóch pierwszych plików. Przy wyświetlaniu pominięto słowa, które nie występowały w danym tekście."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "File number:  0\n",
      "of  ->  3\n",
      "chapter  ->  2\n",
      "a  ->  1\n",
      "all  ->  1\n",
      "an  ->  1\n",
      "and  ->  1\n",
      "audio  ->  1\n",
      "been  ->  1\n",
      "by  ->  1\n",
      "canonical  ->  1\n",
      "contains  ->  1\n",
      "files  ->  1\n",
      "footnotes  ->  1\n",
      "for  ->  1\n",
      "have  ->  1\n",
      "introductions  ->  1\n",
      "make  ->  1\n",
      "numbers  ->  1\n",
      "out  ->  1\n",
      "purpose  ->  1\n",
      "reading  ->  1\n",
      "recording  ->  1\n",
      "script  ->  1\n",
      "set  ->  1\n",
      "stripped  ->  1\n",
      "text  ->  1\n",
      "the  ->  1\n",
      "this  ->  1\n",
      "to  ->  1\n",
      "verse  ->  1\n",
      "\n",
      "File number:  1\n",
      "the  ->  87\n",
      "and  ->  52\n",
      "god  ->  30\n",
      "was  ->  29\n",
      "earth  ->  20\n",
      "it  ->  18\n",
      "of  ->  18\n",
      "there  ->  17\n",
      "let  ->  14\n",
      "to  ->  14\n",
      "in  ->  13\n",
      "that  ->  12\n",
      "after  ->  11\n",
      "over  ->  11\n",
      "waters  ->  11\n",
      "day  ->  10\n",
      "kind  ->  10\n",
      "light  ->  10\n",
      "said  ->  10\n",
      "their  ->  10\n",
      "be  ->  9\n",
      "every  ->  9\n",
      "expanse  ->  9\n",
      "on  ->  9\n",
      "sky  ->  9\n",
      "saw  ->  8\n",
      "them  ->  8\n",
      "good  ->  7\n",
      "called  ->  6\n",
      "evening  ->  6\n",
      "he  ->  6\n",
      "morning  ->  6\n",
      "so  ->  6\n",
      "which  ->  6\n",
      "a  ->  5\n",
      "created  ->  5\n",
      "from  ->  5\n",
      "made  ->  5\n",
      "birds  ->  4\n",
      "darkness  ->  4\n",
      "fruit  ->  4\n",
      "have  ->  4\n",
      "living  ->  4\n",
      "night  ->  4\n",
      "with  ->  4\n",
      "yielding  ->  4\n",
      "creatures  ->  3\n",
      "creeps  ->  3\n",
      "divide  ->  3\n",
      "everything  ->  3\n",
      "for  ->  3\n",
      "image  ->  3\n",
      "lights  ->  3\n",
      "livestock  ->  3\n",
      "multiply  ->  3\n",
      "rule  ->  3\n",
      "sea  ->  3\n",
      "seed  ->  3\n",
      "seeds  ->  3\n",
      "surface  ->  3\n",
      "above  ->  2\n",
      "all  ->  2\n",
      "animals  ->  2\n",
      "bearing  ->  2\n",
      "behold  ->  2\n",
      "bird  ->  2\n",
      "blessed  ->  2\n",
      "creeping  ->  2\n",
      "divided  ->  2\n",
      "dominion  ->  2\n",
      "dry  ->  2\n",
      "fill  ->  2\n",
      "first  ->  2\n",
      "fish  ->  2\n",
      "food  ->  2\n",
      "fruitful  ->  2\n",
      "give  ->  2\n",
      "given  ->  2\n",
      "gods  ->  2\n",
      "grass  ->  2\n",
      "herb  ->  2\n",
      "herbs  ->  2\n",
      "i  ->  2\n",
      "is  ->  2\n",
      "its  ->  2\n",
      "land  ->  2\n",
      "man  ->  2\n",
      "moves  ->  2\n",
      "our  ->  2\n",
      "seas  ->  2\n",
      "thing  ->  2\n",
      "together  ->  2\n",
      "trees  ->  2\n",
      "under  ->  2\n",
      "were  ->  2\n",
      "abound  ->  1\n",
      "also  ->  1\n",
      "an  ->  1\n",
      "animal  ->  1\n",
      "appear  ->  1\n",
      "bears  ->  1\n",
      "beginning  ->  1\n",
      "book  ->  1\n",
      "chapter  ->  1\n",
      "commonly  ->  1\n",
      "creature  ->  1\n",
      "days  ->  1\n",
      "deep  ->  1\n",
      "empty  ->  1\n",
      "female  ->  1\n",
      "fifth  ->  1\n",
      "fly  ->  1\n",
      "formless  ->  1\n",
      "fourth  ->  1\n",
      "gathered  ->  1\n",
      "gathering  ->  1\n",
      "genesis  ->  1\n",
      "great  ->  1\n",
      "greater  ->  1\n",
      "green  ->  1\n",
      "ground  ->  1\n",
      "had  ->  1\n",
      "heavens  ->  1\n",
      "him  ->  1\n",
      "his  ->  1\n",
      "hovering  ->  1\n",
      "large  ->  1\n",
      "lesser  ->  1\n",
      "lets  ->  1\n",
      "life  ->  1\n",
      "likeness  ->  1\n",
      "make  ->  1\n",
      "male  ->  1\n",
      "mark  ->  1\n",
      "middle  ->  1\n",
      "moses  ->  1\n",
      "one  ->  1\n",
      "open  ->  1\n",
      "own  ->  1\n",
      "place  ->  1\n",
      "produce  ->  1\n",
      "saying  ->  1\n",
      "seasons  ->  1\n",
      "second  ->  1\n",
      "set  ->  1\n",
      "signs  ->  1\n",
      "sixth  ->  1\n",
      "spirit  ->  1\n",
      "stars  ->  1\n",
      "subdue  ->  1\n",
      "swarmed  ->  1\n",
      "things  ->  1\n",
      "third  ->  1\n",
      "tree  ->  1\n",
      "two  ->  1\n",
      "very  ->  1\n",
      "will  ->  1\n",
      "winged  ->  1\n",
      "years  ->  1\n",
      "yield  ->  1\n",
      "yielded  ->  1\n",
      "you  ->  1\n",
      "your  ->  1\n",
      "\n",
      "File number:  2\n",
      "the  ->  71\n",
      "of  ->  39\n",
      "and  ->  32\n",
      "man  ->  19\n",
      "to  ->  16\n",
      "god  ->  13\n",
      "is  ->  12\n",
      "yahweh  ->  11\n",
      "a  ->  10\n",
      "he  ->  10\n",
      "his  ->  9\n",
      "it  ->  9\n",
      "in  ->  8\n",
      "from  ->  7\n",
      "had  ->  7\n",
      "earth  ->  6\n",
      "every  ->  6\n",
      "not  ->  6\n",
      "there  ->  6\n",
      "will  ->  6\n",
      "day  ->  5\n",
      "for  ->  5\n",
      "garden  ->  5\n",
      "good  ->  5\n",
      "ground  ->  5\n",
      "river  ->  5\n",
      "that  ->  5\n",
      "tree  ->  5\n",
      "was  ->  5\n",
      "which  ->  5\n",
      "all  ->  4\n",
      "field  ->  4\n",
      "flesh  ->  4\n",
      "him  ->  4\n",
      "made  ->  4\n",
      "name  ->  4\n",
      "out  ->  4\n",
      "were  ->  4\n",
      "you  ->  4\n",
      "be  ->  3\n",
      "became  ->  3\n",
      "but  ->  3\n",
      "done  ->  3\n",
      "eat  ->  3\n",
      "eden  ->  3\n",
      "flows  ->  3\n",
      "formed  ->  3\n",
      "heavens  ->  3\n",
      "into  ->  3\n",
      "land  ->  3\n",
      "on  ->  3\n",
      "one  ->  3\n",
      "seventh  ->  3\n",
      "they  ->  3\n",
      "this  ->  3\n",
      "up  ->  3\n",
      "whole  ->  3\n",
      "work  ->  3\n",
      "animal  ->  2\n",
      "because  ->  2\n",
      "brought  ->  2\n",
      "called  ->  2\n",
      "caused  ->  2\n",
      "comparable  ->  2\n",
      "evil  ->  2\n",
      "finished  ->  2\n",
      "gold  ->  2\n",
      "helper  ->  2\n",
      "its  ->  2\n",
      "knowledge  ->  2\n",
      "life  ->  2\n",
      "living  ->  2\n",
      "my  ->  2\n",
      "no  ->  2\n",
      "put  ->  2\n",
      "rested  ->  2\n",
      "said  ->  2\n",
      "she  ->  2\n",
      "sky  ->  2\n",
      "taken  ->  2\n",
      "them  ->  2\n",
      "through  ->  2\n",
      "took  ->  2\n",
      "went  ->  2\n",
      "wife  ->  2\n",
      "woman  ->  2\n",
      "yet  ->  2\n",
      "alone  ->  1\n",
      "also  ->  1\n",
      "are  ->  1\n",
      "array  ->  1\n",
      "as  ->  1\n",
      "ashamed  ->  1\n",
      "assyria  ->  1\n",
      "bdellium  ->  1\n",
      "bird  ->  1\n",
      "birds  ->  1\n",
      "blessed  ->  1\n",
      "bone  ->  1\n",
      "bones  ->  1\n",
      "both  ->  1\n",
      "breath  ->  1\n",
      "breathed  ->  1\n",
      "call  ->  1\n",
      "chapter  ->  1\n",
      "closed  ->  1\n",
      "commanded  ->  1\n",
      "created  ->  1\n",
      "creation  ->  1\n",
      "creature  ->  1\n",
      "cultivate  ->  1\n",
      "cush  ->  1\n",
      "deep  ->  1\n",
      "die  ->  1\n",
      "dust  ->  1\n",
      "eastward  ->  1\n",
      "euphrates  ->  1\n",
      "fall  ->  1\n",
      "father  ->  1\n",
      "first  ->  1\n",
      "food  ->  1\n",
      "found  ->  1\n",
      "four  ->  1\n",
      "fourth  ->  1\n",
      "freely  ->  1\n",
      "front  ->  1\n",
      "gave  ->  1\n",
      "generations  ->  1\n",
      "genesis  ->  1\n",
      "gihon  ->  1\n",
      "grow  ->  1\n",
      "havilah  ->  1\n",
      "her  ->  1\n",
      "herb  ->  1\n",
      "hiddekel  ->  1\n",
      "history  ->  1\n",
      "holy  ->  1\n",
      "i  ->  1\n",
      "including  ->  1\n",
      "join  ->  1\n",
      "keep  ->  1\n",
      "leave  ->  1\n",
      "livestock  ->  1\n",
      "make  ->  1\n",
      "may  ->  1\n",
      "middle  ->  1\n",
      "mist  ->  1\n",
      "mother  ->  1\n",
      "naked  ->  1\n",
      "names  ->  1\n",
      "nostrils  ->  1\n",
      "now  ->  1\n",
      "onyx  ->  1\n",
      "parted  ->  1\n",
      "pishon  ->  1\n",
      "place  ->  1\n",
      "plant  ->  1\n",
      "planted  ->  1\n",
      "pleasant  ->  1\n",
      "rain  ->  1\n",
      "rib  ->  1\n",
      "ribs  ->  1\n",
      "rivers  ->  1\n",
      "same  ->  1\n",
      "saying  ->  1\n",
      "second  ->  1\n",
      "see  ->  1\n",
      "shall  ->  1\n",
      "sight  ->  1\n",
      "sleep  ->  1\n",
      "slept  ->  1\n",
      "soul  ->  1\n",
      "source  ->  1\n",
      "sprung  ->  1\n",
      "stone  ->  1\n",
      "surely  ->  1\n",
      "surface  ->  1\n",
      "their  ->  1\n",
      "therefore  ->  1\n",
      "third  ->  1\n",
      "till  ->  1\n",
      "vast  ->  1\n",
      "water  ->  1\n",
      "watered  ->  1\n",
      "what  ->  1\n",
      "whatever  ->  1\n",
      "when  ->  1\n",
      "where  ->  1\n",
      "whom  ->  1\n",
      "with  ->  1\n",
      "would  ->  1\n"
     ]
    }
   ],
   "source": [
    "bag_of_words(2, files, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.\n",
    "Zbuduj rzadką macierz wektorów cech term-by-document matrix w której wektory\n",
    "cech ułożone są kolumnowo A m×n = [d1|d2| . . . |dn] (m jest liczbą termów w\n",
    "słowniku, a n liczbą dokumentów)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(files, dictionary):\n",
    "    matrix = []\n",
    "    vector = {}\n",
    "    for file in files:\n",
    "        vector = create_vector(file, dictionary)\n",
    "        matrix.append(vector)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = create_matrix(files, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liczba wierszy:  1100\n",
      "Liczba kolumn:  13675\n"
     ]
    }
   ],
   "source": [
    "print(\"Liczba wierszy: \", len(matrix))\n",
    "print(\"Liczba kolumn: \", len(matrix[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jak widać liczba wierszy macierzy odpowiada liczbie plików tekstowych, a liczba kolumn zgadza się z ilością słów znajdujących się w zdefiniowanym wcześniej słowniku."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.\n",
    "Przetwórz wstępnie otrzymany zbiór danych mnożąc elementy bag-of-words przez\n",
    "inverse document frequency. Operacja ta pozwoli na redukcje znaczenia często występujących\n",
    "słów."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
